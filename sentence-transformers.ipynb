{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Sentence Transformers: Multilingual Sentence, Paragraph, and Image Embeddings using BERT & Co.\n\nThis notebook is implemented based on github repo of Sentence Transformers. Repo can be found [here](https://github.com/UKPLab/sentence-transformers)\n\nIf you want to explore through more functionalties of Sentence Transformers. Check this [link](https://www.sbert.net/) out\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"This framework provides an easy method to compute dense vector representations for **sentences**, **paragraphs**, and **images**. The models are based on transformer networks like BERT / RoBERTa / XLM-RoBERTa etc. and achieve state-of-the-art performance in various task. Text is embedding in vector space such that similar text is close and can efficiently be found using cosine similarity.\n\nFor the **full documentation**, see **[www.SBERT.net](https://www.sbert.net)**.\n","metadata":{}},{"cell_type":"markdown","source":"## Installation\n\nWe recommend **Python 3.6** or higher, **[PyTorch 1.6.0](https://pytorch.org/get-started/locally/)** or higher and **[transformers v4.6.0](https://github.com/huggingface/transformers)** or higher. The code does **not** work with Python 2.7.","metadata":{}},{"cell_type":"code","source":"!pip install -U sentence-transformers\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T14:00:10.437601Z","iopub.execute_input":"2022-03-05T14:00:10.439725Z","iopub.status.idle":"2022-03-05T14:00:24.523083Z","shell.execute_reply.started":"2022-03-05T14:00:10.439122Z","shell.execute_reply":"2022-03-05T14:00:24.521948Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**PyTorch with CUDA**\n\nIf you want to use a GPU / CUDA, you must install PyTorch with the matching CUDA Version. Follow\n[PyTorch - Get Started](https://pytorch.org/get-started/locally/) for further details how to install PyTorch.","metadata":{}},{"cell_type":"markdown","source":"\n## Getting Started\n\nSee [Quickstart](https://www.sbert.net/docs/quickstart.html) in our documenation.\n\n[This example](https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/computing-embeddings/computing_embeddings.py) shows you how to use an already trained Sentence Transformer model to embed sentences for another task.\n\nFirst download a pretrained model.","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T14:01:27.504536Z","iopub.execute_input":"2022-03-05T14:01:27.506061Z","iopub.status.idle":"2022-03-05T14:02:12.493469Z","shell.execute_reply.started":"2022-03-05T14:01:27.506011Z","shell.execute_reply":"2022-03-05T14:02:12.492082Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then provide some sentences to the model.\n","metadata":{}},{"cell_type":"code","source":"sentences = ['This framework generates embeddings for each input sentence',\n    'Sentences are passed as a list of string.', \n    'The quick brown fox jumps over the lazy dog.']\nsentence_embeddings = model.encode(sentences)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T14:02:12.495226Z","iopub.execute_input":"2022-03-05T14:02:12.495502Z","iopub.status.idle":"2022-03-05T14:02:12.675109Z","shell.execute_reply.started":"2022-03-05T14:02:12.495471Z","shell.execute_reply":"2022-03-05T14:02:12.674046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And that's it already. We now have a list of numpy arrays with the embeddings.\n\n","metadata":{}},{"cell_type":"code","source":"for sentence, embedding in zip(sentences, sentence_embeddings):\n    print(\"Sentence:\", sentence)\n    print(\"Embedding:\", embedding)\n    print(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-03-05T14:02:13.326319Z","iopub.execute_input":"2022-03-05T14:02:13.326762Z","iopub.status.idle":"2022-03-05T14:02:13.346334Z","shell.execute_reply.started":"2022-03-05T14:02:13.326728Z","shell.execute_reply":"2022-03-05T14:02:13.345348Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Application Examples\n\nYou can use this framework for:\n\n- [Computing Sentence Embeddings](https://www.sbert.net/examples/applications/computing-embeddings/README.html)\n- [Semantic Textual Similarity](https://www.sbert.net/docs/usage/semantic_textual_similarity.html)\n- [Clustering](https://www.sbert.net/examples/applications/clustering/README.html)\n- [Paraphrase Mining](https://www.sbert.net/examples/applications/paraphrase-mining/README.html)\n - [Translated Sentence Mining](https://www.sbert.net/examples/applications/parallel-sentence-mining/README.html)\n - [Semantic Search](https://www.sbert.net/examples/applications/semantic-search/README.html)\n - [Retrieve & Re-Rank](https://www.sbert.net/examples/applications/retrieve_rerank/README.html) \n - [Text Summarization](https://www.sbert.net/examples/applications/text-summarization/README.html) \n- [Multilingual Image Search, Clustering & Duplicate Detection](https://www.sbert.net/examples/applications/image-search/README.html)\n\nand many more use-cases.\n\nFor all examples, see [examples/applications](https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications).\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T14:02:46.393233Z","iopub.execute_input":"2022-03-05T14:02:46.393893Z","iopub.status.idle":"2022-03-05T14:02:46.402421Z","shell.execute_reply.started":"2022-03-05T14:02:46.393838Z","shell.execute_reply":"2022-03-05T14:02:46.400825Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}