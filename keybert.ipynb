{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# KeyBERT\nKeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to create keywords and keyphrases that are most similar to a document.\n\nCorresponding medium post can be found [here](https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea).\n\nThis notebook is implemented based on github repo of keyBERT. Repo can be found [here](https://github.com/MaartenGr/KeyBERT)","metadata":{}},{"cell_type":"markdown","source":"## Getting Started","metadata":{}},{"cell_type":"markdown","source":"### Installation","metadata":{}},{"cell_type":"code","source":"!pip install keybert\n!pip install flair","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:26:27.590391Z","iopub.execute_input":"2022-03-05T11:26:27.590787Z","iopub.status.idle":"2022-03-05T11:26:36.615098Z","shell.execute_reply.started":"2022-03-05T11:26:27.590753Z","shell.execute_reply":"2022-03-05T11:26:36.614242Z"},"_kg_hide-output":false,"_kg_hide-input":false,"scrolled":true,"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Usage\nThe most minimal example can be seen below for the extraction of keywords:\n\n","metadata":{}},{"cell_type":"code","source":"from keybert import KeyBERT\n\ndoc = \"\"\"\n         Supervised learning is the machine learning task of learning a function that\n         maps an input to an output based on example input-output pairs. It infers a\n         function from labeled training data consisting of a set of training examples.\n         In supervised learning, each example is a pair consisting of an input object\n         (typically a vector) and a desired output value (also called the supervisory signal). \n         A supervised learning algorithm analyzes the training data and produces an inferred function, \n         which can be used for mapping new examples. An optimal scenario will allow for the \n         algorithm to correctly determine the class labels for unseen instances. This requires \n         the learning algorithm to generalize from the training data to unseen situations in a \n         'reasonable' way (see inductive bias).\n      \"\"\"\nkw_model = KeyBERT()\nkeywords = kw_model.extract_keywords(doc)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:20:52.419358Z","iopub.execute_input":"2022-03-05T11:20:52.419663Z","iopub.status.idle":"2022-03-05T11:20:54.437025Z","shell.execute_reply.started":"2022-03-05T11:20:52.419634Z","shell.execute_reply":"2022-03-05T11:20:54.435814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"You can set <b>keyphrase_ngram_range</b> to set the length of the resulting keywords/keyphrases:\n\n","metadata":{}},{"cell_type":"code","source":"kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:30:39.503627Z","iopub.execute_input":"2022-03-05T11:30:39.504020Z","iopub.status.idle":"2022-03-05T11:30:39.677670Z","shell.execute_reply.started":"2022-03-05T11:30:39.503979Z","shell.execute_reply":"2022-03-05T11:30:39.676694Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"To extract keyphrases, simply set <b>keyphrase_ngram_range</b> to (1, 2) or higher depending on the number of words you would like in the resulting keyphrases:","metadata":{}},{"cell_type":"code","source":"kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2), stop_words=None)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:30:40.743315Z","iopub.execute_input":"2022-03-05T11:30:40.743721Z","iopub.status.idle":"2022-03-05T11:30:41.085648Z","shell.execute_reply.started":"2022-03-05T11:30:40.743686Z","shell.execute_reply":"2022-03-05T11:30:41.084655Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"We can highlight the keywords in the document by simply setting hightlight:","metadata":{}},{"cell_type":"code","source":"keywords = kw_model.extract_keywords(doc, highlight=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:21:53.643728Z","iopub.execute_input":"2022-03-05T11:21:53.644414Z","iopub.status.idle":"2022-03-05T11:21:53.796555Z","shell.execute_reply.started":"2022-03-05T11:21:53.644359Z","shell.execute_reply":"2022-03-05T11:21:53.795703Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Max Sum Similarity\nTo diversify the results, we take the 2 x top_n most similar words/phrases to the document. Then, we take all top_n combinations from the 2 x top_n words and extract the combination that are the least similar to each other by cosine similarity.","metadata":{}},{"cell_type":"code","source":"kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', \n                              use_maxsum=True, nr_candidates=20, top_n=5)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:33:26.649669Z","iopub.execute_input":"2022-03-05T11:33:26.649989Z","iopub.status.idle":"2022-03-05T11:33:27.226617Z","shell.execute_reply.started":"2022-03-05T11:33:26.649954Z","shell.execute_reply":"2022-03-05T11:33:27.225690Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Maximal Marginal Relevance \nTo diversify the results, we can use Maximal Margin Relevance (MMR) to create keywords / keyphrases which is also based on cosine similarity. The results with high diversity:","metadata":{}},{"cell_type":"code","source":"kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', \n                              use_mmr=True, diversity=0.7)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:34:29.679338Z","iopub.execute_input":"2022-03-05T11:34:29.679623Z","iopub.status.idle":"2022-03-05T11:34:29.907000Z","shell.execute_reply.started":"2022-03-05T11:34:29.679593Z","shell.execute_reply":"2022-03-05T11:34:29.905994Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The results with low diversity:","metadata":{}},{"cell_type":"code","source":"kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', \n                              use_mmr=True, diversity=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:48:10.478400Z","iopub.execute_input":"2022-03-05T11:48:10.478758Z","iopub.status.idle":"2022-03-05T11:48:10.714253Z","shell.execute_reply.started":"2022-03-05T11:48:10.478719Z","shell.execute_reply":"2022-03-05T11:48:10.713301Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Embedding Models\nKeyBERT supports many embedding models that can be used to embed the documents and words:\n\n* Sentence-Transformers\n* Flair\n* Spacy\n* Gensim\n* USE\n\nClick [here](https://maartengr.github.io/KeyBERT/guides/embeddings.html) for a full overview of all supported embedding models.\n\n","metadata":{}},{"cell_type":"markdown","source":"### Sentence-Transformers\nYou can select any model from sentence-transformers [here](https://www.sbert.net/docs/pretrained_models.html) and pass it through KeyBERT with model:\n\n","metadata":{}},{"cell_type":"code","source":"from keybert import KeyBERT\nkw_model = KeyBERT(model='all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:47:14.578849Z","iopub.execute_input":"2022-03-05T11:47:14.580366Z","iopub.status.idle":"2022-03-05T11:47:16.620659Z","shell.execute_reply.started":"2022-03-05T11:47:14.580292Z","shell.execute_reply":"2022-03-05T11:47:16.619351Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Or select a SentenceTransformer model with your own parameters:\n\n","metadata":{}},{"cell_type":"code","source":"from keybert import KeyBERT\nfrom sentence_transformers import SentenceTransformer\n\nsentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\nkw_model = KeyBERT(model=sentence_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:47:16.651291Z","iopub.execute_input":"2022-03-05T11:47:16.651607Z","iopub.status.idle":"2022-03-05T11:47:18.725797Z","shell.execute_reply.started":"2022-03-05T11:47:16.651565Z","shell.execute_reply":"2022-03-05T11:47:18.724722Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"\n### Flair\n[Flair](https://github.com/flairNLP/flair) allows you to choose almost any embedding model that is publicly available. Flair can be used as follows:\n\n","metadata":{}},{"cell_type":"code","source":"from keybert import KeyBERT\nfrom flair.embeddings import TransformerDocumentEmbeddings\n\nroberta = TransformerDocumentEmbeddings('roberta-base')\nkw_model = KeyBERT(model=roberta)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:39:52.395596Z","iopub.execute_input":"2022-03-05T11:39:52.395935Z","iopub.status.idle":"2022-03-05T11:40:10.936966Z","shell.execute_reply.started":"2022-03-05T11:39:52.395861Z","shell.execute_reply":"2022-03-05T11:40:10.935993Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## References\n@misc\n{grootendorst2020keybert,<br>\n  author       = {Maarten Grootendorst},<br>\n  title        = {KeyBERT: Minimal keyword extraction with BERT.},<br>\n  year         = 2020,<br>\n  publisher    = {Zenodo},<br>\n  version      = {v0.3.0},<br>\n  doi          = {10.5281/zenodo.4461265},<br>\n  url          = {https://doi.org/10.5281/zenodo.4461265}\n}","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}